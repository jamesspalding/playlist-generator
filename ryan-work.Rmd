
```{r}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


```{r}
#Step 1: clean data

songs = read.csv("spotify_songs.csv") 
songs = distinct(songs, track_id, .keep_all = T) %>% #removing duplicate songs
  select(c(-track_album_id, -track_album_name, #removing album info
           -playlist_name, -playlist_id, #removing playlist info
           -mode, -duration_ms)) #removing unnecessary info
songs
```

```{r, warning=FALSE, message=FALSE}
# Idea for Step 2... Use popularity as response variable to run stepwise model to determine the significant predictor variables

# playlist_genre: 6 types
# playlist_subgenre: 24 types... not important?

# attach variables
songs <- attach(songs)

# set variables to easier variable names
y <- track_popularity; x1 <- playlist_genre; x2 <- danceability; x3 <- energy; x4 <- key; x5 <- loudness; x6 <- speechiness
x7 <- acousticness; x8 <- instrumentalness; x9 <- liveness; x10 <- valence; x11 <- tempo

x1 <- factor(x1)  # set x1 as a categorical factor

# generate a smaller sample to look at sample plots
set.seed(123)
sample.data <- sort(sample(1:28356, 100, replace = FALSE)) 

# examine all plots of predictor variables against response variable
pairs(cbind(y[c(sample.data)],x1[c(sample.data)],x2[c(sample.data)],x3[c(sample.data)],x4[c(sample.data)]))
pairs(cbind(y[c(sample.data)],x5[c(sample.data)],x6[c(sample.data)],x7[c(sample.data)],x8[c(sample.data)]))
pairs(cbind(y[c(sample.data)],x9[c(sample.data)],x10[c(sample.data)],x11[c(sample.data)])) # all plots seem okay??

# should test for correlation between variables?
```


```{r}
# setting a random training dataset from the song data to run the Stepwise process
set.seed(123)
training.data <- sort(sample(1:28356, 10000, replace = FALSE)) 

# creating the variables holding the training data
y.training <- y[training.data]; x1.training <- x1[training.data]; x2.training <- x2[training.data]; x3.training <- x3[training.data]; x4.training <- x4[training.data]
x5.training <- x5[training.data]; x6.training <- x6[training.data]; x7.training <- x7[training.data]; x8.training <- x8[training.data]
x9.training <- x9[training.data]; x10.training <- x10[training.data]; x11.training <- x11[training.data]

# finding the validation dataset, all 
validation.data <- setdiff(1:28356, training.data)

# creating the remaining variables holding the validation data
y.validation <- y[validation.data]; x1.validation <- x1[validation.data]; x2.validation <- x2[validation.data]; x3.validation <- x3[validation.data]; x4.validation <- x4[validation.data]
x5.validation <- x5[validation.data]; x6.validation <- x6[validation.data]; x7.validation <- x7[validation.data]; x8.validation <- x8[validation.data]
x9.validation <- x9[validation.data]; x10.validation <- x10[validation.data]; x11.validation <- x11[validation.data]

### 1st Stepwise step
# gather p-values
pval.x1.latin=coefficients(summary(lm(y.training~x1.training)))[2,4]
pval.x1.pop=coefficients(summary(lm(y.training~x1.training)))[3,4]
pval.x1.randb=coefficients(summary(lm(y.training~x1.training)))[4,4]
pval.x1.rap=coefficients(summary(lm(y.training~x1.training)))[5,4]
pval.x1.rock=coefficients(summary(lm(y.training~x1.training)))[6,4]
pval.x2=coefficients(summary(lm(y.training~x2.training)))[2,4]
pval.x3=coefficients(summary(lm(y.training~x3.training)))[2,4]
pval.x4=coefficients(summary(lm(y.training~x4.training)))[2,4]
pval.x5=coefficients(summary(lm(y.training~x5.training)))[2,4]
pval.x6=coefficients(summary(lm(y.training~x6.training)))[2,4]
pval.x7=coefficients(summary(lm(y.training~x7.training)))[2,4]
pval.x8=coefficients(summary(lm(y.training~x8.training)))[2,4]
pval.x9=coefficients(summary(lm(y.training~x9.training)))[2,4]
pval.x10=coefficients(summary(lm(y.training~x10.training)))[2,4]
pval.x11=coefficients(summary(lm(y.training~x11.training)))[2,4]

# test which p-value is the smallest
pvals=c(pval.x1.latin,pval.x1.pop,pval.x1.randb,pval.x1.rap,pval.x1.rock,pval.x2,pval.x3,pval.x4,pval.x5,pval.x6,pval.x7,pval.x8,pval.x9,pval.x10,pval.x11)
which(pvals==min(pvals))  # 2nd entry in pvals returns the smallest p-value, which is the pop genre of variable x1 (playlist_genre)

pvals[2]  # 3.030825e-80 < .05



### 2nd Stepwise step
# gather p-values where x1 is already in the model
pval.x1.x2=coefficients(summary(lm(y.training~x1.training+x2.training)))[7,4]
pval.x1.x3=coefficients(summary(lm(y.training~x1.training+x3.training)))[7,4]
pval.x1.x4=coefficients(summary(lm(y.training~x1.training+x4.training)))[7,4]
pval.x1.x5=coefficients(summary(lm(y.training~x1.training+x5.training)))[7,4]
pval.x1.x6=coefficients(summary(lm(y.training~x1.training+x6.training)))[7,4]
pval.x1.x7=coefficients(summary(lm(y.training~x1.training+x7.training)))[7,4]
pval.x1.x8=coefficients(summary(lm(y.training~x1.training+x8.training)))[7,4]
pval.x1.x9=coefficients(summary(lm(y.training~x1.training+x9.training)))[7,4]
pval.x1.x10=coefficients(summary(lm(y.training~x1.training+x10.training)))[7,4]
pval.x1.x11=coefficients(summary(lm(y.training~x1.training+x11.training)))[7,4]

# test which p-value is the smallest
pvals.x1=c(pval.x1.x2,pval.x1.x3,pval.x1.x4,pval.x1.x5,pval.x1.x6,pval.x1.x7,pval.x1.x8,pval.x1.x9,pval.x1.x10,pval.x1.x11)
which(pvals.x1==min(pvals.x1))  # variable x8 (instrumentalness) is found to return the smallest p-value when x1 (playlist_genre) is already in the model

pvals.x1[7]  # 1.311291e-21 < .05

coefficients(summary(lm(y.training~x1.training+x8.training)))  # each category of x1 (playlist_genre) still remains significant when x8 (instrumentalness) is added to the model



### 3rd Stepwise step
# gather p-values where x1 and x8 are already in the model
pval.x1.x8.x2=coefficients(summary(lm(y.training~x1.training+x8.training+x2.training)))[8,4]
pval.x1.x8.x3=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training)))[8,4]
pval.x1.x8.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x4.training)))[8,4]
pval.x1.x8.x5=coefficients(summary(lm(y.training~x1.training+x8.training+x5.training)))[8,4]
pval.x1.x8.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x6.training)))[8,4]
pval.x1.x8.x7=coefficients(summary(lm(y.training~x1.training+x8.training+x7.training)))[8,4]
pval.x1.x8.x9=coefficients(summary(lm(y.training~x1.training+x8.training+x9.training)))[8,4]
pval.x1.x8.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x10.training)))[8,4]
pval.x1.x8.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x11.training)))[8,4]

# test which p-value is the smallest
pvals.x1.x8=c(pval.x1.x8.x2,pval.x1.x8.x3,pval.x1.x8.x4,pval.x1.x8.x5,pval.x1.x8.x6,pval.x1.x8.x7,pval.x1.x8.x9,pval.x1.x8.x10,pval.x1.x8.x11)
which(pvals.x1.x8==min(pvals.x1.x8))  # variable x3 (energy) is found to return the smallest p-value when x1 (playlist_genre) and x8 (instrumentalness) are already in the model

pvals.x1.x8[2]  # 3.277445e-13 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training))) # most categories of x1 (playlist_genre) are still significant, and x8 (instrumentalness) is still significant when x3 (energy) is added to the model



### 4th Stepwise step
# gather p-values where x1, x8, and x3 are already in the model
pval.x1.x8.x3.x2=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x2.training)))[9,4]
pval.x1.x8.x3.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x4.training)))[9,4]
pval.x1.x8.x3.x5=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training)))[9,4]
pval.x1.x8.x3.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x6.training)))[9,4]
pval.x1.x8.x3.x7=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x7.training)))[9,4]
pval.x1.x8.x3.x9=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x9.training)))[9,4]
pval.x1.x8.x3.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x10.training)))[9,4]
pval.x1.x8.x3.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x11.training)))[9,4]

# test which p-value is the smallest
pvals.x1.x8.x3=c(pval.x1.x8.x3.x2,pval.x1.x8.x3.x4,pval.x1.x8.x3.x5,pval.x1.x8.x3.x6,pval.x1.x8.x3.x7,pval.x1.x8.x3.x9,pval.x1.x8.x3.x10,pval.x1.x8.x3.x11)
which(pvals.x1.x8.x3==min(pvals.x1.x8.x3))  # variable x5 (loudness) is found to return the smallest p-value when x1, x8, and x3 are already in the model

pvals.x1.x8.x3[3]  # 9.176121e-42 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training)))  # all categories of x1 (playlist_genre), x8 (instrumentalness), and x3 (energy) are still significant when x5 (loudness) is added to the model



### 5th Stepwise step
# gather p-values where x1, x8, x3, and x5 are already in the model
pval.x1.x8.x3.x5.x2=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training)))[10,4]
pval.x1.x8.x3.x5.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x4.training)))[10,4]
pval.x1.x8.x3.x5.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x6.training)))[10,4]
pval.x1.x8.x3.x5.x7=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x7.training)))[10,4]
pval.x1.x8.x3.x5.x9=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x9.training)))[10,4]
pval.x1.x8.x3.x5.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x10.training)))[10,4]
pval.x1.x8.x3.x5.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x11.training)))[10,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5=c(pval.x1.x8.x3.x5.x2,pval.x1.x8.x3.x5.x4,pval.x1.x8.x3.x5.x6,pval.x1.x8.x3.x5.x7,pval.x1.x8.x3.x5.x9,pval.x1.x8.x3.x5.x10,pval.x1.x8.x3.x5.x11)
which(pvals.x1.x8.x3.x5==min(pvals.x1.x8.x3.x5))  # variable x2 (danceability) is found to return the smallest p-value when variables x1, x8, x3, and x5 are already in the model

pvals.x1.x8.x3.x5[1]  # 2.225464e-10 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training)))  # all categories of x1 (playlist_genre), x8 (instrumentalness), x3 (energy), and x5 (loudness) are still significant when x2 (danceability) is added to the model



### 6th Stepwise step
# gather p-values where x1, x8, x3, x5, and x2 are already in the model
pval.x1.x8.x3.x5.x2.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x4.training)))[11,4]
pval.x1.x8.x3.x5.x2.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x6.training)))[11,4]
pval.x1.x8.x3.x5.x2.x7=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training)))[11,4]
pval.x1.x8.x3.x5.x2.x9=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x9.training)))[11,4]
pval.x1.x8.x3.x5.x2.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x10.training)))[11,4]
pval.x1.x8.x3.x5.x2.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x11.training)))[11,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5.x2=c(pval.x1.x8.x3.x5.x2.x4,pval.x1.x8.x3.x5.x2.x6,pval.x1.x8.x3.x5.x2.x7,pval.x1.x8.x3.x5.x2.x9,pval.x1.x8.x3.x5.x2.x10,pval.x1.x8.x3.x5.x2.x11)
which(pvals.x1.x8.x3.x5.x2==min(pvals.x1.x8.x3.x5.x2))  # variable x7 (acousticness) is found to return the smallest p-value when x1, x8, x3, x5, and x2 are already in the model

pvals.x1.x8.x3.x5.x2[3]  # 3.029837e-06 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training)))  # all categories of x1 (playlist_genre), x8 (instrumentalness), x3 (energy), x5 (loudness), and x2 (danceability) are still significant when x7 (acousticenss) is added to the model



### 7th Stepwise step
# gather p-values where x1, x8, x3, x5, x2, and x7 are already in the model
pval.x1.x8.x3.x5.x2.x7.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x4.training)))[12,4]
pval.x1.x8.x3.x5.x2.x7.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x6.training)))[12,4]
pval.x1.x8.x3.x5.x2.x7.x9=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training)))[12,4]
pval.x1.x8.x3.x5.x2.x7.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x10.training)))[12,4]
pval.x1.x8.x3.x5.x2.x7.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x11.training)))[12,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5.x2.x7=c(pval.x1.x8.x3.x5.x2.x7.x4,pval.x1.x8.x3.x5.x2.x7.x6,pval.x1.x8.x3.x5.x2.x7.x9,pval.x1.x8.x3.x5.x2.x7.x10,pval.x1.x8.x3.x5.x2.x7.x11)
which(pvals.x1.x8.x3.x5.x2.x7==min(pvals.x1.x8.x3.x5.x2.x7))  # variable x9 (livenss) is found to return the smallest p-value when x1, x8, x3, x5, x2, and x7 are already in the model

pvals.x1.x8.x3.x5.x2.x7[3]  # 0.003860144 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training)))  # most categories of x1 (playlist_genre), x8 (instrumentalness), x3 (energy), x5 (loudness), x2 (danceability), and x7 (acousticness) are still significant when x9 (liveness) is added to the model



### 8th Stepwise step
# gather p-values where x1, x8, x3, x5, x2, x7, and x9 are already in the model
pval.x1.x8.x3.x5.x2.x7.x9.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x4.training)))[13,4]
pval.x1.x8.x3.x5.x2.x7.x9.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x6.training)))[13,4]
pval.x1.x8.x3.x5.x2.x7.x9.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x10.training)))[13,4]
pval.x1.x8.x3.x5.x2.x7.x9.x11=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training)))[13,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5.x2.x7.x9=c(pval.x1.x8.x3.x5.x2.x7.x9.x4,pval.x1.x8.x3.x5.x2.x7.x9.x6,pval.x1.x8.x3.x5.x2.x7.x9.x10,pval.x1.x8.x3.x5.x2.x7.x9.x11)
which(pvals.x1.x8.x3.x5.x2.x7.x9==min(pvals.x1.x8.x3.x5.x2.x7.x9))  # variable x11 (tempo) is found to return the smallest p-value when x1, x8, x3, x5, x2, x7, and x9 are already in the model

pvals.x1.x8.x3.x5.x2.x7.x9[4]  # 0.008217235 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training)))  # all categories of x1 (playlist_genre), x8 (instrumentalness), x3 (energy), x5 (loudness), x2 (danceability), x7 (acousticness), and x9 (liveness) are still significant when x11 (tempo) is added to the model



### 9th Stepwise step
# gather p-values where x1, x8, x3, x5, x2, x7, x9, and x11 are already in the model
pval.x1.x8.x3.x5.x2.x7.x9.x11.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x4.training)))[14,4]
pval.x1.x8.x3.x5.x2.x7.x9.x11.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x6.training)))[14,4]
pval.x1.x8.x3.x5.x2.x7.x9.x11.x10=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x10.training)))[14,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5.x2.x7.x9.x11=c(pval.x1.x8.x3.x5.x2.x7.x9.x11.x4,pval.x1.x8.x3.x5.x2.x7.x9.x11.x6,pval.x1.x8.x3.x5.x2.x7.x9.x11.x10)
which(pvals.x1.x8.x3.x5.x2.x7.x9.x11==min(pvals.x1.x8.x3.x5.x2.x7.x9.x11))  # variable x10 (valence) is found to return the smallest p-value when x1, x8, x3, x5, x2, x7, x9, and x11 are already in the model

pvals.x1.x8.x3.x5.x2.x7.x9.x11[3]  # 0.04035236 < .05

coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x10.training)))  # all categories of x1 (playlist_genre), x8 (instrumentalness), x3 (energy), x5 (loudness), x2 (danceability), x7 (acousticness), x9 (liveness), and x11 (tempo) are still significant when x10 (valence) is added to the model



### 10th Stepwise step
# gather p-values where x1, x8, x3, x5, x2, x7, x9, x11, and x10 are already in the model
pval.x1.x8.x3.x5.x2.x7.x9.x11.x10.x4=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x10.training+x4.training)))[15,4]
pval.x1.x8.x3.x5.x2.x7.x9.x11.x10.x6=coefficients(summary(lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x10.training+x6.training)))[15,4]

# test which p-value is the smallest
pvals.x1.x8.x3.x5.x2.x7.x9.x11.x10=c(pval.x1.x8.x3.x5.x2.x7.x9.x11.x10.x4,pval.x1.x8.x3.x5.x2.x7.x9.x11.x10.x6)
which(pvals.x1.x8.x3.x5.x2.x7.x9.x11.x10==min(pvals.x1.x8.x3.x5.x2.x7.x9.x11.x10))  # variable x4 (key) is found to return the smallest p-value when x1, x8, x3, x5, x2, x7, x9, x11, and x10 are already in the model

pvals.x1.x8.x3.x5.x2.x7.x9.x11.x10[1]  # 0.4950643 > .05, so we should stop and not add any other variables to the model.
                                       # Therefore, we have our best model containing x1 (playlist_genre), x8 (instrumentalness),
                                       # x3 (energy), x5 (loudness), x2 (danceability), x7 (acousticness),
                                       # x9 (livenss), x11 (tempo), and x10 (valence).

# best model found from the Stepwise process on the training dataset
best.model.training <- lm(y.training~x1.training+x8.training+x3.training+x5.training+x2.training+x7.training+x9.training+x11.training+x10.training)

summary(best.model.training)$coef
```


  The Stepwise process on the training data gives the best linear regression model for the edm category of the playlist genre to be $$\widehat{Popularity} = 46.84327861 - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$, and for the latin category to be $$\widehat{Popularity} = (46.84327861 + 6.76104261) - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$, and for the pop category to be $$\widehat{Popularity} = (46.84327861 + 12.39529693) - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$, and for the r&b category to be $$\widehat{Popularity} = (46.84327861 + 2.30816516) - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$, and for the rap category to be $$\widehat{Popularity} = (46.84327861 + 7.70061302) - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$, and lastly for the rock category of playlist genre to be $$\widehat{Popularity} = (46.84327861 + 10.38302918) - 7.33963458(Instrumentalness) - 20.96812717(Energy) + 1.44788261(Loudness) + 13.68405666(Danceability) + 6.28231307(Acousticness) - 4.12188004(Liveness) + 0.02403758(Tempo) - 2.32546662(Valence)$$.

